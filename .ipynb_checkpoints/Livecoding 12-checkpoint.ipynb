{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get URL's for S&P 500 Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting requests_html\n",
      "  Downloading requests_html-0.2.2-py2.py3-none-any.whl (10 kB)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting pyquery\n",
      "  Downloading pyquery-1.4.1-py2.py3-none-any.whl (22 kB)\n",
      "Collecting parse\n",
      "  Downloading parse-1.14.0.tar.gz (29 kB)\n",
      "Requirement already satisfied: requests in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from requests_html) (2.22.0)\n",
      "Collecting fake-useragent\n",
      "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.8.2-py2-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cssselect>0.7.9\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: lxml>=2.1 in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from pyquery->requests_html) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from requests->requests_html) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from requests->requests_html) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from requests->requests_html) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from requests->requests_html) (1.25.8)\n",
      "Collecting soupsieve>=1.2\n",
      "  Downloading soupsieve-1.9.5-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: backports.functools-lru-cache; python_version < \"3\" in /Users/mikestragapede/Library/Python/2.7/lib/python/site-packages (from soupsieve>=1.2->beautifulsoup4->bs4->requests_html) (1.6.1)\n",
      "Building wheels for collected packages: bs4, parse, fake-useragent\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py2-none-any.whl size=1272 sha256=5a85974c8c5800d169ea71b9166f2c15fe4f87df6c5b78b276bee2848a5f1a03\n",
      "  Stored in directory: /Users/mikestragapede/Library/Caches/pip/wheels/98/b9/dc/90f1e36fc6bf9564491a69c9c3d7ae38b8f72986256e416be6\n",
      "  Building wheel for parse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for parse: filename=parse-1.14.0-py2-none-any.whl size=23462 sha256=3fd38078858ad0f6adf451072a3f78841a657cca4554c5a1c6f2cc94e55df2e6\n",
      "  Stored in directory: /Users/mikestragapede/Library/Caches/pip/wheels/e2/40/58/34f8c47ec636e31cddac75a7ada99884ce81b167db5df7456b\n",
      "  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py2-none-any.whl size=13487 sha256=0e686deb15a184b66e72931691d1fbfce02ca5753beaf784bde4089d98fc4f2a\n",
      "  Stored in directory: /Users/mikestragapede/Library/Caches/pip/wheels/31/cd/fd/01593bc9cfb3f38fc789c2646fce5dab2d9fef4af01547d447\n",
      "Successfully built bs4 parse fake-useragent\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4, cssselect, pyquery, parse, fake-useragent, requests-html\n",
      "Successfully installed beautifulsoup4-4.8.2 bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.14.0 pyquery-1.4.1 requests-html-0.2.2 soupsieve-1.9.5\n"
     ]
    }
   ],
   "source": [
    "#!pip install requests_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests_html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b434d6ad749e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrequests_html\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTMLSession\u001b[0m \u001b[0;31m#HTMLSession is how it opens pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHTMLSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests_html'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession #HTMLSession is how it opens pages\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "session = HTMLSession()\n",
    "r = session.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3e934a951f0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#blunt force\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlins\u001b[0m \u001b[0;31m#gives you all of the links from the source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0;31m#contians links that are absolute and relative links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute_links\u001b[0m \u001b[0;31m#gives you only absolute links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "#blunt force\n",
    "r.html.lins #gives you all of the links from the source\n",
    "            #contians links that are absolute and relative links\n",
    "r.html.absolute_links #gives you only absolute links\n",
    "\n",
    "#get the table\n",
    "#r.html.find('table')\n",
    "#r.html.find('table')[0] get the first table\n",
    "#r.html.find('#constituents') returns the table with the constituent id\n",
    "table = r.html.find('#constituents')[0]\n",
    "table # prints a list, you want the table. Adding the brackets gives you the table\n",
    "table.text #gives you just the text\n",
    "table.html #print html\n",
    "\n",
    "#blunt force the table\n",
    "table.absolute_links #extracts all the urls from that specfic table ...but too many, we want only wikipedia\n",
    "pd.read_html(table.html) #prints the table in text (not what we want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's loop over the rows\n",
    "table.find('tr') #gives a list of rows\n",
    "table.find('tr')[0].text #header\n",
    "table.find('tr')[1].text\n",
    "\n",
    "table_rows = table.find('tr')\n",
    "\n",
    "colinks = []\n",
    "for row in table_rows[1:]:\n",
    "    a_link = list(row.find('td')[1].absolute_links)[0]\n",
    "    colinks.append(a_link)\n",
    "colinks\n",
    "len(colinks) # they're 505 firms in the S&P500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Clean That Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from requests_html import HTMLSession #HTMLSession is how it opens pages\n",
    "\n",
    "#open the page\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "session = HTMLSession()\n",
    "r = session.get(url)\n",
    "\n",
    "table = r.html.find('#constituents')[0]\n",
    "table_rows = table.find('tr')\n",
    "\n",
    "colinks = []\n",
    "for row in table_rows[1:]:\n",
    "    a_link = list(row.find('td')[1].absolute_links)[0]\n",
    "    colinks.append(a_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
